#import "@preview/algorithmic:1.0.5"
#import algorithmic: (
  style-algorithm, 
  algorithm-figure
)
#import "@preview/ctheorems:1.1.3": *
#import "@preview/mitex:0.2.4": *
#import "@preview/numbly:0.1.0": numbly

#show strong: set text(blue)
#show: thmrules.with(qed-symbol: $square$)

#let wk_report_name = "中山大学 MA7259《机器学习》期末作业"
#let header_name = "中山大学 MA7259《机器学习》期末作业"
#let project_name = "基于3D-UNet模型的小样本肺部肿瘤分割研究"
#let name_no = "何瑞杰 25110801"

#let const = "constant"
#let bx = $bold(x)$
#let mx = $macron(bx)$
#let pd = $p_("data")$
#let ps = $p_(sigma)$
#let qs = $q_(sigma)$
#let pt = $p_(theta)$
#let dd = "d"
#let ito = $"It"hat("o")$
#let be = $bold(epsilon)$
#let prod = $product$
#let int = $integral$

#let KL = $D_("KL")$

// Theorem environments
#let theorem = thmbox("theorem", "定理", fill: rgb("#eeffee"))
#let corollary = thmplain(
  "corollary",
  "推论",
  base: "theorem",
  titlefmt: strong
)
#let definition = thmbox("definition", "定义", inset: (x: 1.2em, top: 1em))
#let example = thmplain("example", "示例").with(numbering: none)
#let proof = thmproof("proof", "证明")

#let redText(t) = {text(red)[$t$]}
#let blueText(t) = {text(blue)[$t$]}
#let greenText(t) = {text(green)[$t$]}
#let orangeText(t) = {text(orange)[$t$]}

#set page(
  paper: "a4",
  numbering: "1",
  header: header_name + " | " + name_no,
)

#set par(
  first-line-indent: 2em,
  justify: true,
)

#set heading(numbering: "1.")

#v(5em)

#align(
  center, 
  text(12pt)[#wk_report_name\ ] + v(0.5em) 
        + text(17pt)[#project_name\ ]
        + text(12pt)[\ #name_no]
)

#v(5em)

#align(center, [摘#h(2em)要])
#pad(
  left: 6em, right: 6em, 
  [
    #lorem(100)
  ]
)

#outline()

#pagebreak()

= 研究背景与目的

#h(2em) 非小细胞肺癌（NSCLC）作为肺癌中最常见的类型，占据了大约 85% 的肺癌病例，主要包含鳞状细胞癌、腺癌和大细胞癌等亚型。与小细胞肺癌相比，NSCLC 的生长速度通常较慢，治疗手段也更为多样化，通常取决于肿瘤的具体类型、发展阶段以及患者整体的健康状况。在 NSCLC 的诊断和治疗过程中，CT扫描扮演着至关重要的角色。它能提供关于肿瘤大小、形状和位置的详细信息，帮助医生确定病变的精确阶段，并指导手术和放疗计划。此外，CT 图像对于监测肿瘤对治疗的响应和检测复发或转移至关重要。

本研究尝试使用深度学习方法，基于病人 CT 影像中由医护人员手动标注的 NSCLC 数据学习一个 3D 分割模型，输入为处理过的 CT 影像数据，输出为分割后的影像数据，其中包含可能的病灶位置。凭借已在数据集上训练好的鲁棒模型，可以快速帮助病人和医生定位可能的病灶位置，节省时间以便后续的处理治疗。

= 数据集及初步分析
== 数据集介绍

#h(2em) 本研究采用的数据为数据集是医学图像分割十项全能挑战赛  (Medical Segmentation Decathlon, MSD)#cite(<MSD-Dataset-antonelli2022medical>) 中的第 6 个子任务，即 MSD Lung Tumours 数据集#cite(<MSD-Paper-simpson2019large>)。其目标是从 CT 图像中分割出肺部肿瘤，MSD 选择该数据集的原因是“在大的背景中分割出小目标”。该数据集包含 96 例（实为 95 例）NSCLC 患者的薄层CT扫描，官方划分为 64 例训练集（实为 63 例）和 32 例测试集，其中测试集可以通过官网提交分割结果进行测试。MSD Lung Tumours数据集是Medical Segmentation Decathlon (MSD)国际挑战赛的重要组成部分，由安东内利等学者于2018年在MICCAI会议上首次公开发布。该数据集旨在系统评估机器学习算法在非小细胞肺癌CT影像分割任务中的泛化能力与鲁棒性挑战，作为迄今规模最大且临床异质性最强的公开医学图像分割基准之一，其数据全部来源于The Cancer Imaging Archive获取的经病理证实的NSCLC患者术前薄层CT扫描，经严格脱敏处理后以NIfTI标准格式呈现，并在CC-BY-SA 4.0协议下支持学术与商业用途的开放获取。整个数据集共收录96例三维CT影像，其中64例作为训练集并配有像素级标注，32例作为独立测试集用于算法性能评估，目标区域明确界定为原发肿瘤实体范围，标注由单一专家完成，涵盖肿瘤坏死与实性成分的完整勾画。

该数据集在MSD挑战赛框架中被明确归类为小目标-小样本-大视野任务的典型代表，其设计初衷在于真实再现临床实践中算法面临的三大核心瓶颈。首要挑战在于目标尺度的极端不平衡性，肿瘤病灶体积相较于全肺扫描视野占比不足百分之一，这种悬殊比例要求算法必须具备对微小结构的精准识别能力，同时导致传统Dice重叠度指标对单像素偏差呈现高度敏感，显著增加了模型优化的难度。其次，数据集刻意设置了训练数据的稀缺性条件，64例训练样本的规模远低于深度学习模型的常规数据需求，迫使算法必须在有限样本条件下学习高维特征空间，从而直接检验模型的数据效率与过拟合抑制能力。此外，数据集充分呈现了解剖与病理层面的异质性特征，病例覆盖不同肿瘤位置、大小、形态学表现及周围组织浸润模式，且CT扫描协议存在多中心差异，包括层厚、重建算法和造影剂使用等方面的变异，全面考验算法跨域泛化的稳健性。

从技术规格来看，该数据集采用多中心CT扫描作为成像模态，图像维度为三维体数据，平均尺寸约为512×512×300体素，体素分辨率呈各向异性特点，平面分辨率介于0.6至0.8毫米之间，而层间距则在1至1.5毫米范围。所有图像均经过标准化预处理流程，强度归一化采用基于0.5至99.5百分位计算的鲁棒最小-最大缩放方法，以消除不同扫描仪间的灰度差异，同时坐标系统统一转换为RAS（右-前-上）标准朝向，确保数据空间方向的一致性。

MSD挑战赛为该数据集设计了双重指标评估框架，以确保性能度量的临床相关性。Dice Similarity Coefficient (DSC)作为主要排名指标，用于衡量体素级重叠程度，其中冠军方法nnU-Net在此任务上取得了中位DSC达0.71（四分位距0.58至0.82）的优异成绩，显著优于第二名方法的0.69中位DSC。Normalized Surface Dice (NSD)则作为辅助度量，基于表面距离计算并设定2毫米的临床容忍误差，该指标对小目标分割的边界精度具有更强的判别能力。竞赛结果充分验证了该任务的极端挑战性，部分低性能算法在肿瘤分割上的平均DSC甚至低于0.1，而nnU-Net通过自适应数据增强与模型集成策略，成功将性能差距控制在0.56以上，证明了自动化方法在小样本肿瘤分割任务中实现临床级精度的可行性。

该数据集的研究价值远超算法排名基准本身，已成为医学AI泛化能力研究的关键试金石。其首要贡献在于推动了自配置框架的发展，该任务的攻克直接催生了nnU-Net等无需手动调参的分割系统，证实通过自动化设计可达顶尖性能。同时，数据集为小样本学习范式提供了标准化评估平台，为后续元学习与域适应研究奠定基础。从临床转化视角看，NSCLC放疗靶区勾画与术后监测存在巨大人力成本，自动化分割技术可将单病例处理时间从30分钟缩短至分钟级别，展现出直接的应用潜力与经济效益。研究者目前可通过AWS开放数据注册库便捷获取数据，并利用nnUNetv2_convert_MSD_dataset工具实现一键格式转换，推荐使用nnU-Net v2框架快速实现SOTA性能。对于定制化研究需求，应重点参考论文中提及的Instance Normalization、Leaky ReLU激活函数以及针对性采样策略等关键技术设计，这些方法已被证实是处理小目标、小数据集任务的核心要素。

#figure(
  grid(
    columns: (56.5%, 43.5%),
    image("assets/snapshot0001.png"),
    image("assets/snapshot0004.png"),
    image("assets/snapshot0002.png"),
    image("assets/snapshot0005.png"),
    image("assets/snapshot0003.png"),
    image("assets/snapshot0006.png"),
  ),
  caption: []
)


== 探索性数据分析


=== 灰度分布
#image("assets/gray_scale_histplot.png")

=== 病灶大小



#h(2em)

#pagebreak()

= 方法与模型
== 3D-UNet

=== 2D-UNet 和 3D-UNet

U-Net自2015年问世以来，凭借其编码器-解码器对称结构与跳跃连接设计，迅速成为医学图像分割领域的事实标准。该架构通过下采样路径捕捉多尺度语义特征，再通过上采样路径恢复空间分辨率，并在相同分辨率的编码器-解码器层间建立特征拼接，有效融合了高层上下文信息与低层定位细节。然而，原始U-Net本质上是面向二维切片的框架，在处理CT、MRI等三维医学影像时，通常采用逐层推理后拼接的策略，这不仅破坏了层间空间连续性，也无法利用z轴方向的关键解剖上下文。为克服这一局限，Çiçek等人提出的3D U-Net将网络中的所有操作单元三维化，实现了端到端的体素级预测，为后续nnU-Net等自动化框架奠定了核心网络基础。

三维化改造并非简单的算子替换，而是针对医学数据特性的系统性重构。首先，所有卷积核扩展为3×3×3，最大池化与上采样也相应变为2×2×2，使感受野在三个正交方向均衡扩展。在Xenopus肾脏分割任务中，网络输入为132×132×116体素的三通道图像块，每个输出体素对应约155×155×180微米³的上下文范围，这种设计确保模型能够感知完整的肾小管三维走向。其次，通道数调整策略发生关键变化：为避免信息压缩导致的梯度阻塞，3D U-Net在最大池化操作前即完成通道数翻倍，而非池化后。这一细节对深度三维网络尤为重要，因为体素级预测对特征复用效率的要求远高于二维情形。此外，批归一化层的应用策略也针对性优化，针对医学数据批量通常仅为1的特点，研究发现训练和测试阶段均采用当前批次的动态统计量，而非预计算的全局统计量，可显著提升小样本下的收敛稳定性。

=== 稀疏标注学习

3D U-Net最具启发性的创新在于其对稀疏标注数据的处理能力，这一特性与医学影像标注成本高昂的现实困境高度契合。传统全监督分割需要逐层勾画感兴趣区域，工作量随数据维度呈立方级增长。3D U-Net通过引入加权softmax损失函数，将未标注体素的损失权重显式设为零，使梯度计算仅作用于用户提供的少量标注切片。这种机制允许训练过程中忽略大量未标注体素，同时利用三维空间的结构连续性自动推断其类别。在实验设置中，标注者仅需在xy、xz、yz三个正交方向均匀采样少量切片——例如每个方向5至7片——即可覆盖整个体积的关键解剖变异。这些标注切片被赋予正式类别标签，而其余所有体素统一标记为"未标注"类别并赋予零权重，网络因此学会从稀疏监督信号中泛化出稠密的三维分割结果。

数据增强策略在稀疏标注场景下扮演更为关键的角色。3D U-Net采用实时弹性形变增强，在32体素间距的三维网格上采样来自高斯分布（标准差为4）的随机位移向量，通过B样条插值生成平滑形变场，同步应用于图像与标注掩码。这种非刚性变换能够模拟器官的形态学变异，有效扩充训练样本的多样性。由于增强过程在训练迭代时动态执行，每次前向传播都处理不同的形变样本，理论上可生成无限训练数据，这对仅有2-3个完整标注体积的医学任务至关重要。加权损失的另一层含义体现在类别平衡上：针对背景与肾小管体素数量严重失衡的问题，网络自动下调背景权重、提升前景权重，确保少数类结构在优化过程中获得充分关注。这种多层次的权重调控机制，使模型在极稀疏监督下仍能稳定收敛。

=== 双模式应用架构

3D U-Net框架天然支持两种临床应用范式，分别对应不同的数据准备策略与性能预期。在半自动模式下，用户的目标是为单个或少数几个新病例生成分割结果，且不希望进行全容积标注。此时，用户可在每个体积中交互式标注少量正交切片，网络即时学习并预测完整的三维掩码。这种模式的价值在于将标注工作量压缩90%以上，同时保持较高精度。实验数据显示，当标注切片覆盖约9%的体素时，交叉验证IoU可达0.856至0.872，接近全监督性能。值得注意的是，随着标注密度提升，网络性能呈现非线性增长：初始阶段每增加一片标注可带来约0.15 IoU的显著提升，但超过临界点后收益逐渐递减，这表明三维空间连续性已能充分推断未标注区域的结构。

全自动模式则适用于大规模队列研究，此时需要预先构建具有代表性的稀疏标注训练库。理想情况下，数十个病例的少量标注切片组合起来，可形成覆盖群体变异的监督信号。3D U-Net在此场景下展现出相对于二维实现的本质优势：当在Xenopus三个肾脏体积上进行交叉验证时，三维架构平均IoU为0.704，而二维切片独立处理基线仅为0.547，性能差距超过28%。这一差距源于三维卷积核能够编码层间解剖依赖关系，例如肾小管的连续走向或肿瘤的浸润性生长模式，这些在单张切片中无法捕捉。然而，全自动模式对数据一致性要求更高：当训练集与测试集存在显著域偏移时，批归一化可能因统计量不匹配而反向优化，提示实际应用中需确保训练数据的代表性分布。


#h(2em)

#pagebreak()

= 实验与结论

#h(2em)

#pagebreak()

= 计算机程序代码说明

#pagebreak()

#bibliography("ref.bib",   // 你的 BibTeX 文件
              title: "参考文献",
              style: "ieee", 
              full: true
)

