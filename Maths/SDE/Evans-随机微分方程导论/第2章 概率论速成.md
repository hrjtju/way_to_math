# 第二章 概率论速成
## 2.1 基本定义
让我们从一个谜题开始。

### 2.1.1 Bertrand 悖论
> **问题 2.1（Bertrand 悖论）** 
> 假如平面上有一个长为 $2$ 的的圆，然后我们 <font color="purple">随机地</font> 选一条弦。与以该圆同圆心，半径为 $1$ 的圆相交的概率是多少？

* 解法 1：由于每条弦由其中点唯一确定，因此与小圆相交的概率为小圆面积除以大圆面积，即 $\displaystyle \frac{1}{4}$.
* 解法 2：由于圆的旋转对称性，对于每一条弦，我们都能旋转整个图形，使得该弦是垂直的。大圆直径为 $4$，小圆直径为 $2$，弦与小圆相交，那它一定与（旋转后的）小圆直径相交（且垂直），因此概率为小圆直径除以大圆直径，即 $\displaystyle\frac{1}{2}$.
* 解法 3：由于圆的旋转对称性，我们总能旋转整个图形，使得它的一个端点位于大圆的最左侧。考虑弦与大圆水平直径的夹角 $\theta$，可知它落在 $\displaystyle\left[ -\frac{\pi}{2}, \frac{\pi}{2} \right]$ 之间，由几何关系可得，弦与小圆相交时，$\theta$ 落在 $\displaystyle \left[ -\frac{\pi}{6}, \frac{\pi}{6} \right]$ 之间。因此概率为这两个区间长度之比，也即 $\displaystyle \frac{1}{3}$
![600](Pasted%20image%2020250601153030.png)

真是离谱到家了，同样的问题居然有三个不同的答案！

### 2.1.2 概率空间
一个很自然的疑问就是，上面到底出了什么问题？（如果上面没问题，那数学大厦就要塌了）注意到我把”随机地“三个字用颜色标出来了，问题就出在这里：我们没有良好的定义这里的随机到底是”怎么随机“的。为了解决这样的问题，我们引入概率空间的概念。

我们先有一个非空集合 $\Omega$，其中的子集我们称之为”事件“。

> **定义 2.2（$\sigma$-代数）** 
> 一个 $\sigma$ 代数指的是非空集合 $\Omega$ 上的一个子集族 $\mathcal{U}$，并满足下面的条件
> * $\varnothing, \Omega \in \mathcal{U}$
> * 如果 $A \in \mathcal{U}$，那么其补集 $A^{c} \in \mathcal{U}$
> * 如果一列集合 $A_{1}, \dots \in \mathcal{U}$，那么有 $$\displaystyle \bigcup_{k=1}^{\infty} A_{k},  \bigcap_{k=1}^{\infty} A_{k} \in \mathcal{U}.$$

> **定义 2.3 （概率测度）** 
> 设 $\mathcal{U}$ 是 $\Omega$ 上的一个 $\sigma$-代数，我们称 $$P: \mathcal{U} \rightarrow [0, 1]$$是一个概率测度，如果它满足下面的条件
> 1. $P(\varnothing) = 0$, $P(\Omega) = 1$
> 2. 如果一列集合 $A_{1}, \dots \in \mathcal{U}$，则 $$P\left[\bigcup_{k=1}^{\infty} A_{k} \right] \leqslant \sum\limits_{k=1}^{\infty}P(A_{k}) $$
> 3. 如果一列集合  $A_{1}, \dots \in \mathcal{U}$ 互不相交，则 $$P\left[\bigcup_{k=1}^{\infty} A_{k} \right] = \sum\limits_{k=1}^{\infty}P(A_{k}) $$

从这个定义我们得到：假如 $A \subset B$，就有 $P(A) \leqslant P(B)$，因为 $P(B) = P(B) + P(B - A) \geqslant P(A)$。

> **定义 2.4（概率空间）** 
> $\Omega$ 是一个非空集合，$\mathcal{U}$ 是其上的一个 $\sigma$-代数，$P$ 是 $\mathcal{U}$ 上的概率测度；我们称三元组 $(\Omega, \mathcal{U}, P)$ 是一个概率空间。

> **术语约定 2.5**
> 1. 集合 $A \in \mathcal{U}$ 被称为一个**事件**，$\omega \in \Omega$ 被称为**样本点**
> 2. $P(A)$ 是事件 $A$ 的**概率**
> 3. 如果一个属性，对除了概率为零得事件以外均为真，我们称其为 **几乎必然成立 (almost surely, 简写为 a.s.)**。

概率空间是概率论的必要设定，在讨论或解决任何问题之前，我们都要明确它所指的概率空间是什么。现在回头看之前的 Bertrand 悖论，我们不难发现三个解法对悖论中的”随机“作出了不同的解读，对应着三个不同的概率空间。

下面给出一些典型的概率空间的示例。

> **示例 2.6 （Borel $\sigma$-代数、概率密度）**
> 包含了 $\mathbb{R}^{n}$ 上所有开集的 $\sigma$-代数称为 **Borel $\sigma$-代数**，记为 $\mathcal{B}$。假设 $f$ 是非负的，并有 $\displaystyle \int_{\mathbb{R}^{n}} f\,\mathrm{d}x = 1$。我们可以对任意的 $B \in \mathcal{B}$ 定义 $$P(B) = \int_{B} f(x) \, \mathrm d{x} $$于是 $(\mathbb{R}^{n}, \mathcal{B}, P)$ 是一个概率空间，$f$ 为概率测度 $P$ 的概率密度。

> **示例 2.7 （Dirac 测度）**
> 选定 $\mathbb{R}^{n}$ 中的一个点 $x_{0}$，对任意的 $B \in \mathcal{B}$，定义 $$P(B) \coloneqq \begin{cases}1 & \text{if }x_{0} \in B \\0  & \text{if }x_{0} \notin B\end{cases}$$则 $(\mathbb{R}^{n}, \mathcal{B}, P)$ 是一个概率空间，我们称 $P$ 为集中在 $x_{0}$ 处的 **Dirac 点质量**，并将其记作 $\delta_{x_{0}}$。

> **示例 2.8 （Buffon 投针问题）**
> 现在我们要向一个平面上随机地投长度为 $1$ 的针。平面上有一簇间隔距离为 $2$ 的平行直线，求针投下后与其中一条平行线相交的概率。首先我们要找一个概率空间。记 $h$ 为投下的针的中心到最近一条平行线的距离，$\displaystyle \theta < \frac{\pi}{2}$ 为针所在直线与平行线的夹角。于是我们有 $\displaystyle \Omega = \left[0, \frac{\pi}{2}\right) \times [0, 1]$，其中前者对应 $\theta$ 的取值，后者对应 $h$ 的取值。接下来令 $\mathcal{U}$ 是 $\Omega$ 的 Borel 子集，并令概率测度 $P$ 为 $$P(B) = \frac{2(\text{area of }B)}{\pi}\quad \text{for each }B \in \mathcal{U},$$这其实就是Borel子集与 $\Omega$ 相交的**大小**与 $\Omega$ 本身大小的比值。接下来我们记针与平行线相交为事件 $A$，由几何关系可知此时 $\displaystyle \frac{h}{\sin \theta} \leqslant \frac{1}{2}$。于是就有 $\displaystyle A = \left\{  (\theta, h) \in \Omega: h \leqslant \sin \frac{\theta}{2}  \right\}$，这样我们就能求得事件 $A$ 的概率 $$P(A) = \frac{2(\text{area of }A)}{\pi} = \frac{2}{\pi}\int_{0}^{\pi/2} {\frac{1}{2}\sin \theta} \, \mathrm d{\theta} = \frac{1}{\pi}. $$


### 2.1.3 随机变量

> **定义 2.9 （随机变量，$\mathcal{U}$-可测）** 设 $(\Omega, \mathcal{U}, P)$ 是一个概率空间，一个映射 $$\boldsymbol{X}: \Omega \rightarrow \mathbb{R}^{n}$$被称为一个 $n$ 维随机变量，如果对任意 $B \in \mathcal{B}$，我们有 $$\boldsymbol{X}^{-1}(B) \in \mathcal{U}.$$我们也称 $\boldsymbol{X}$ 是 $\mathcal{U}$-可测的。
> 这说的其实是 $\boldsymbol{X}$ 是 $\mathcal{U}$ 到 $\mathcal{B}$ 的一个**可测映射**？

我们注意这里的 $X^{-1} \in \mathcal{U}$，这样定义是比像要更好的，需要记住的是，$\mathcal{U}$ 和 $\mathcal{B}$ 都是 $\sigma$-代数，所以必须满足定义 2.2 中所述的若干条件。考虑 $B_{1}, B_{2} \in \mathcal{B}$，我们理应有
$$
\begin{align}
\boldsymbol{X}^{-1}(B_{1} \cup B_{2}), \boldsymbol{X}^{-1}(B_{1} \cap B_{2}), \boldsymbol{X}^{-1}(B_{1}^{c})\in \mathcal{U}.
\end{align}
$$
事实上，我们有集合的交并补可以穿透原像算子，也即
$$
f^{-1}(A \,\square\, B) = f^{-1}(A) \,\square\, f^{-1}(B),\quad f^{-1}(A^{c}) = [f^{-1}(A)]^{c}
$$
其中 $\square \in \{ \cup, \cap \}$。假如我们将原像算子换成看似更加自然的求像集操作，也即对任意 $U \in \mathcal{U}$，有 $f(U) \in \mathcal{B}$。由类似地逻辑，我们需要验证对任意的 $U, V \in \mathcal{U}$，都有
$$
\boldsymbol{X}(U \,\square\, V) \in \mathcal{B}, \boldsymbol{X}(U^{c}) \in \mathcal{B}.
$$
而我们可以适当地构造反例让上面的条件不再成立。

> **术语约定 2.10**
> 1. 我们一般写 $\boldsymbol{X}$，而不写 $\boldsymbol{X}(\omega)$
> 2. 我们一般写 $P(\boldsymbol{X} \in B)$，而不写 $P(\boldsymbol{X}^{-1}(B))$

> **示例 2.11 （示性函数，简单函数）** 考虑集合 $A \in \mathcal{U}$，它的示性函数定义为 $$\chi_{A}(\omega) := \begin{cases} 1, & \omega \in A\\ 0, & \omega \notin A, \end{cases}$$这是一个随机变量。更一般地，考虑 $A_{1}, \dots, A_{m} \in \mathcal{U}$，并有 $\displaystyle \Omega = \bigcup_{i=1}^{m} A_{i}$，$a_{i} \in \mathbb{R}$，于是 $$X = \sum\limits_{i=1}^{m} a_{i}\chi_{A_{i}}$$是一个随机变量，我们称其为简单函数（simple function）
> 简单函数是可覆盖概率空间 $\Omega$ 的一族 $\mathcal{U}$ 中元素之示性函数的线性组合。

> **引理 2.12 （随机变量生成的 $\sigma$-代数）** 设 $\boldsymbol{X}: \Omega \rightarrow \mathbb{R}^{n}$ 是一个随机变量，则 $$\mathcal{U}(\boldsymbol{X}) := \{ \boldsymbol{X}^{-1}(B): B \in \mathcal{B} \}$$是一个 $\sigma$-代数，被称为随机变量 $\boldsymbol{X}$ 生成的 $\sigma$-代数。
> 显然，$\mathcal{U}(\boldsymbol{X})$ 要比原来的 $\mathcal{U}$ 小。

这是使得 $\boldsymbol{X}$ 可测的最小的 $\mathcal{U}$ 的子$\sigma$-代数。

**证明.** 不难发现，这个引理需要用到前面提到的集合运算能够穿透映射原像的一个结果。
首先，空集和全集 $\Omega$肯定是 $\mathcal{U}(\boldsymbol{X})$的集合。对于前者，考虑 $\boldsymbol{X}^{-1}(\varnothing) = \{ \omega \in \Omega: f(\omega) \in \varnothing \}$，因为 $f(\omega) \in \varnothing$ 永远不可能为真，因此只有 $X^{-1}(\varnothing) = \varnothing$。另一方面，考虑 $\boldsymbol{X}^{-1}(\mathbb{R}^{n})$（由拓扑学知识，我们知道 $\mathbb{R}^{n}$ 是它自己的的开子集），我们得到 $\boldsymbol{X}^{-1}(\mathbb{R}^{n}) = \Omega$。
然后我们证明第二条，也即对任意 $B \in \mathcal{B}$，都有 $\boldsymbol{X}^{-1}(B)^{c} \in \mathcal{U}(\boldsymbol{X})$。事实上，我们来证明 $\boldsymbol{X}^{-1}(B)^{c}$ 事实上就是 $\boldsymbol{X}^{-1}(B^{c})$：
$$
\begin{align}
\boldsymbol{X}^{-1}(B)^{c} &= \{ \omega \in \Omega: f(\omega) \in B \}^{c}\\
&= \{ \omega \in \Omega: f(\omega) \in B^{c} \} = \boldsymbol{X}^{-1}(B^{c})
\end{align}
$$
用类似的方法，我们也可以证明该集族对可数并和可数交都封闭。于是 $\mathcal{U}(\boldsymbol{X})$ 是一个 $\sigma$-代数，且它不能再小了：从里面拿出一个元素都会使得 $\boldsymbol{X}$ 在拿掉元素后的集族下不可测。    Q.E.D.

> <font color="red"><b>注释 2.13</b></font> 很重要的一点是，我们从概率论的角度可以说 “$\mathcal{U}(\boldsymbol{X})$ 包含了 $\boldsymbol{X}$ 的相关信息”。假如另一个随机变量 $\boldsymbol{Y}$ 可以写成 $\boldsymbol{Y} = \Phi(\boldsymbol{X})$，其中 $\Phi$ 是某个 “合理的” 函数，那 $\boldsymbol{Y}$ 也是 $\mathcal{U}(\boldsymbol{X})$-可测的。另一方面，假如存在一个 $\mathcal{U}(\boldsymbol{X})$-可测的随机变量 $\boldsymbol{Y}$，那么一定存在一个函数 $\Phi$，使得 $\boldsymbol{Y} = \Phi(\boldsymbol{X})$。
> 事实上，这样的 $\Phi$ 称为 **可测映射**，这是了可测空间范畴的态射。

### 2.1.4 随机过程
本节中我们介绍取决于时间的随机变量。

> **定义 2.14 （随机过程，采样路径）** 一个随机变量的集合 $\{ \boldsymbol{X}(t): t \geqslant 0 \}$ 被称为一个随机过程。对每个 $\omega \in \Omega$，映射 $t \mapsto \boldsymbol{X}(t, \omega)$ 称为一个采样路径。

> <font color="red"><b>术语约定 2.15</b></font>
> 有的地方也使用 $\boldsymbol{X}_{t}$ 而不是 $\boldsymbol{X}(t)$ 指称一个关于变量 $t$ 的随机过程 

## 2.2 期望和方差
### 2.2.1 关于测度的积分

> **定义 2.16 （随机变量 $X$ 关于概率测度 $P$ 的积分）**
> 设 $(\Omega, \mathcal{U}, P)$ 是概率空间，$\displaystyle X = \sum\limits_{i=1}^{k} a_i\chi_{A_{i}}$ 是一个实值简单随机变量，定义 $X$ 的积分为 $$\int_{\Omega} X \, \mathrm dP := \sum\limits_{i=1}^{k} a_{i}P(A_{i}) $$如果 $X$ 是非负的随机变量，我们用简单随机变量积分的上确界定义它的积分 $$\int_{\Omega} X \, \mathrm dP := \sup_{Y \leqslant X, Y\text{ simple}} \int_{\Omega} Y \, \mathrm dP.$$对于一般的实值随机变量 $X:\Omega \rightarrow \mathbb{R}$，定义其积分值为正部的积分减去负部的积分（若二者至少有一个有限）：$$\int_{\Omega} X \, \mathrm dP := \int_{\Omega} X^{+} \, \mathrm dP - \int_{\Omega} X^{-} \, \mathrm dP,$$其中 $X^{+} := \max\{ X, 0 \}$，$X^{-} := \max\{ -X, 0 \}$；容易验证 $X = X^{+} - X^-$。

> **注解 2.16**
> 1. 事实上，这里的积分就是随机变量 $X$ 在概率测度 $P$ 下的 **Lebesgue 积分**，不难发现我们可以将其理解为对 “值域进行分割”。
> 2. 我们假设后面出现的所有积分都存在且有限

> **术语约定 2.17**
> 对于 $n$ 维随机变量 $\boldsymbol{X}: \Omega \rightarrow \mathbb{R}^{n}$，其中 $\boldsymbol{X} = (X^{1}, \dots, X^{n})$，我们将其积分写为 $$\int_{\Omega} \boldsymbol{X} \, \mathrm dP = \left[ \int_{\Omega} X^{1} \, \mathrm d{P}, \cdots, \int_{\Omega} X^{n} \, \mathrm d{P}  \right]$$

> **定义 2.18 （期望，方差）**
> 假设 $\boldsymbol{X}: \Omega \rightarrow \mathbb{R}^{n}$ 是一个向量值的随机变量，称 $$E(\boldsymbol{X}):= \int_{\Omega} \boldsymbol{X} \, \mathrm dP $$为它（在概率测度 $P$ 下）的期望（或均值），称 $$V(\boldsymbol{X}) := \int_{\Omega} \|\boldsymbol{X} - E(\boldsymbol{X})\|_{2}^{2}  \, \mathrm dP $$为它的方差。不难验证 $V(\boldsymbol{X}) = E(\|\boldsymbol{X}\|^{2}_{2}) - \|E(\boldsymbol{X})\|^{2}_{2}$.

### 2.2.2 分布函数

本节中我们默认概率空间是 $(\Omega, \mathcal{U}, P)$，并有一个随机变量 $\boldsymbol{X} : \Omega \rightarrow \mathbb{R}^{n}$。

> **术语约定 2.19**
> 取向量 $x = (x_{1}, \dots, x_{n}), y = (y_{1}, \dots, y_{n}) \in \mathbb{R}^{n}$，如果对每一个 $i = 1, \dots, n$，都有 $x_{i} \leqslant y_{i}$，我们就说 $x  \leqslant y$。
> 事实上这在 $\mathbb{R}^{n}$ 上构造了一个偏序。

> **定义 2.20 （分布函数）**
> 随机变量 $\boldsymbol{X}$ 的分布函数 $F_{\boldsymbol{X}}: \mathbb{R}^{n} \rightarrow [0, 1]$ 定义如下 $$F_{\boldsymbol{X}}(x) \coloneqq P(\boldsymbol{X} \leqslant x), \quad \text{for all }x \in \mathbb{R}^{n}$$更一般地，对于多个随机变量 $\boldsymbol{X}_{1}, \dots, \boldsymbol{X}_{m}: \Omega \rightarrow \mathbb{R}^{n}$，它们的**联合分布函数** $F_{\boldsymbol{X}_{1}, \dots, \boldsymbol{X}_{m}}: (\mathbb{R}^{n})^{m} \rightarrow [0, 1]$ 定义为 $$F_{\boldsymbol{X}_{1}, \dots, \boldsymbol{X}_{m}}(x_{1}, \dots, x_{m}) \coloneqq P(\boldsymbol{X}_{1} \leqslant x_{1}, \dots, \boldsymbol{X}_{m} \leqslant x_{m})$$其中 $x_{k} \in \mathbb{R}^{k}, k = 1, \dots, m$

> **定义 2.21（密度函数）**
> $\boldsymbol{X}: \Omega \rightarrow \mathbb{R}^{n}$ 是随机变量，$F = F_{\boldsymbol{X}}$ 是它的分布函数。假如存在一个非负可积的函数 $f: \mathbb{R}^{n} \rightarrow \mathbb{R}$ 使得 $$F(x) = F(x_{1}, \dots, x_{n}) = \int_{-\infty}^{x_{1}} \cdots  \int_{-\infty}^{x_{n}} f(y_{1}, \dots, y_{n}) \, \mathrm d{y_{n}}\cdots   \, \mathrm dy_{1} $$则我们称 $f$ 是 $\boldsymbol{X}$ 的密度函数。进而可以得到对任意的 $B \in \mathcal{B}$，都有 $$P(\boldsymbol{X} \in B) = \int_{B} f(x) \, \mathrm d x.$$

> **引理 2.22**
> 如果随机变量 $\boldsymbol{X}$ 的分布函数 $F_{\boldsymbol{x}}$ 存在对应的密度函数 $f$，并考虑 $g: \mathbb{R}^{n} \rightarrow \mathbb{R}$ ，且 $g(\boldsymbol{X})$ 是可积的（这里 $g$ 可积和 $g(\boldsymbol{X})$ 可积是一个意思吗？）则有 $$E(g(\boldsymbol{X})) = \int_{\mathbb{R}^{n}} g(x)f(x) \, \mathrm dx $$特别地，有 $$E(\boldsymbol{X}) = \int_{\mathbb{R}^{n}} xf(x) \, \mathrm dx,\quad V(\boldsymbol{X}) = \int_{\mathbb{R}^{n}} |x - m|^{2}f(x) \, \mathrm dx  $$其中 $m \coloneqq E(\boldsymbol{X})$。

> **注释 2.23**
> 这样一来我们就能通过在 $\mathbb{R}^{n}$ 上求积分的方式得到 $E(\boldsymbol{X})$ 和 $V(\boldsymbol{X})$。但需要注意概率空间 $(\boldsymbol{\Omega}, \mathcal{U}, P)$ 是 “难以看见的”，而我们所看见的是经过 $\boldsymbol{X}$ 映射后在 $\mathbb{R}^{n}$ 中的东西。
> 事实上，所有概率论中感兴趣的量都可以在 $\mathbb{R}^{n}$ 中通过密度函数 $f$ 求得

**证明.** 我们从简单的情况开始。首先假设 $g$ 是 $\mathbb{R}^{n}$ 上的一个简单函数：
$$
g = \sum\limits_{i=1}^{m} b_{i} \chi_{B_{i}}, \quad B_{i} \in \mathcal{B}
$$
这样就有
$$
E(g(\boldsymbol{X})) = \sum\limits_{i=1}^{m} b_{i} \int_{_{\Omega}} \chi_{B_{i}}(\boldsymbol{X}) \, \mathrm dP = \sum\limits_{i=1}^{m} b_{i}P(X \in B_{i}) 
$$
另一方面
$$
\int_{\mathbb{R}^{n}} g(x)f(x) \, \mathrm dx = \sum\limits_{i=1}^{m} b_{i} \int_{\mathbb{R}^{n}} f(x)\chi_{B_{i}} \, \mathrm dx = \sum\limits_{i=1}^{m} b_{i} \int_{B_{i}} f(x) \, \mathrm dx = \sum\limits_{i=1}^{m} b_{i}P(x \in B_{i}).   
$$
这样我们就得到当 $g$ 是简单函数时引理成立。由于一般的函数可由简单函数逼近，对于一般的函数上面的引理也成立。 Q.E.D.


## 2.3 独立性
### 2.3.1 条件概率

考虑概率空间 $(\Omega, \mathcal{U}, P)$，其中 $A, B \in \mathcal{U}$ 是两个事件，且 $P(B) > 0$。我们希望找到下面的 **条件概率** 的合理定义。
$$
P(A|B) = \text{给定 }B\text{ 条件下 }A\text{ 的概率}
$$

![[Pasted image 20250714131124.png]]
我们可以画出这张图，$\Omega$ 里面有一个点 $w \in B$，我们想知道它属于 $A$ 的概率。我们可以将 $B$ 视为一个新的概率空间：$\tilde{\Omega} \coloneqq B$，$\tilde{\mathcal{U}} \coloneqq \{ C \cup B: C \in \mathcal{U} \}$，$\displaystyle \tilde{P} \coloneqq \frac{P}{P(B)}$。我们立刻有 $\tilde{P}(\tilde{\Omega}) = 1$，$\displaystyle \tilde{P}(A \cap B) = \frac{P(A \cap B)}{P(B)}$

> **定义 2.24（条件概率）**
> 事件 $B$ 满足 $P(B) > 0$，定义事件 $B$ 发生下事件 $A$ 的条件概率为 $$P(A|B) \coloneqq \frac{P(A \cap B)}{P(B)}.$$


### 2.3.2 独立事件

明确了条件概率后我们就要看看事件之间相互独立是指什么了。这应该对应着 $P(A|B) = P(A)$，这可以理解为知道事件 $B$ 的发生与否对事件 $A$ 的发生与否没有贡献。因此假设 $P(B) > 0$，我们就有 $P(A \cap B) = P(A)P(B)$，下面我们依照这个事实对独立性做一个定义

> **定义 2.25（两事件的独立性）**
> 两个事件 $A$ 和 $B$ 独立，是指 $$P(A \cap B) = P(A)P(B)$$

假如两个事件 $A$ 和 $B$ 相互独立，那么 $A^{c}$ 和 $B$ ，$A$ 和 $B^{c}$，$A^{c}$ 和 $B^{c}$ 也是相互独立的。进一步地我们可以将定义扩展到多个事件

> **定义 2.26（相互独立的事件族）**
> 一族事件 $A_{1}, \dots, A_{n}, \dots$ 是相互独立是指对任取的 $1 \leqslant k_{1} < k_{2} <\cdots<k_{m}$，有 $$P(A_{k_{1}} \cap A_{k_{2}} \cap \cdots  \cap A_{k_{m}}) = P(A_{k_{1}})P(A_{k_{2}}) \cdots  P(A_{k_{m}}).$$

我们还可以定义 $\sigma$-代数 之间的独立关系

> **定义 2.27（相互独立的 $\sigma$-代数族）**
> 一组子 $\sigma$-代数 $\mathcal{U}_{i} \subset \mathcal{U}$，其中 $i = 1, \dots$ 是独立的，是指对任取的 $1 \leqslant k_{1} < k_{2} <\cdots<k_{m}$ 和其中的任意事件 $A_{k_{i}} \in \mathcal{U}_{k}$，有 $$P(A_{k_{1}} \cap A_{k_{2}} \cap \cdots  \cap A_{k_{m}}) = P(A_{k_{1}})P(A_{k_{2}}) \cdots  P(A_{k_{m}}).$$

### 2.3.3 独立随机变量

接下来我们考虑随机变量的独立性。

> **定义 2.28（相互独立的随机变量族）**
> 考虑一族随机变量 $\boldsymbol{X}_{i}: \Omega \rightarrow \mathbb{R}^{n}, i = 1, \dots$，假如对任意整数 $k \geqslant 2$，任取的 Borel 集 $B_{1}, \dots, B_{k} \subset \mathbb{R}^{n}$，有 $$P(\boldsymbol{X}_{1} \in B_{1}, \boldsymbol{X}_{2} \in B_{2}, \dots, \boldsymbol{X}_{k} \in B_{k}) = P(\boldsymbol{X}_{1} \in B_{1})P(\boldsymbol{X}_{2} \in B_{2})\cdots P(\boldsymbol{X}_{k} \in B_{k}),$$就称 $\boldsymbol{X}_{1}, \dots$ 是相互独立的。这相当于说它们生成的 $\sigma$-代数 $\{ \mathcal{U}_{i} \}_{i=1}^{\infty}$ 是相互独立的。


> **示例 2.29（Rademacher 函数）**
> 取 $\Omega = [0, 1)$，$\mathcal{U}$ 为 $[0, 1)$ 上的 Borel 子集，$P$ 为 Lebesgue 测度。对 $n = 1, 2, \dots$，定义 $$X_{n}(\omega) = \begin{cases}1 &\displaystyle  \text{if } \frac{k}{2^{n}} \leqslant \omega \leqslant  \frac{k+1}{2^{n}}, k \in 2\mathbb{Z} \\-1  & \displaystyle \text{if }  \frac{k}{2^{n}} \leqslant \omega \leqslant  \frac{k+1}{2^{n}}, k \in 2\mathbb{Z}+1\end{cases}, \quad 0 \leqslant \omega \leqslant 1.$$这样的函数叫做 Rademacher 函数，可以验证它们是相互独立的。仔细观察可以验证，该函数与小数的二进制表示有关。如果二进制小数 $x$ 的第 $k$ 位小数是 $0$，则 $X_{k}(x) = 1$，反之则为零。因此给定一个 $x \in [0, 1)$，序列 $X_{1}(x), X_{2}(x), \dots$ 与 $x$ 的二进制表示一一对应。现在我们考虑 $e_{1}, \dots, e_{k} \in \{ -1, +1 \}$，并验证 $$P(\boldsymbol{X}_{1} = e_{1}, \dots, \boldsymbol{X}_{k} = e_{k}) = P(\boldsymbol{X}_{1} = e_{1})\cdots P(\boldsymbol{X}_{k} = e_{k}).$$上面式子的左边其实是确定了二进制小数前 $k$ 位的值，因此取值的浮动只能在 $\displaystyle \frac{1}{2^{k}}$ 的范围内，我们考虑 Lebesgue 测度，因此左边就等于 $\displaystyle \frac{1}{2}$。接下来考虑右边。观察函数可以得到，不论下标和 $e_{i}$ 取何值，都有 $\displaystyle P(\boldsymbol{X}_{i} = e_{i}) \equiv \frac{1}{2}$，而右边刚好有 $k$ 项。由于 $k$ 是任取的，我们就证明了 $\boldsymbol{X}_{1}, \dots$ 是相互独立的。
> <font color="red">这其实也是符合直觉的，因为二进制小数部分的每一位是可以自由选择的，不存在选择了某一位之后另外一位的取值就受到影响。</font>


> **定理 2.30（相互独立的随机变量族划分后构造的新随机变量相互独立）** 
> 考虑相互独立的随机变量 $\boldsymbol{X}_{1}, \dots, \boldsymbol{X}_{m+n}$，并考虑函数 $f: (\mathbb{R}^{k})^{n} \rightarrow \mathbb{R}$，$g: (\mathbb{R}^{k})^{m} \rightarrow \mathbb{R}$，则 $$\boldsymbol{Y} \coloneqq f(\boldsymbol{X}_{1}, \dots, \boldsymbol{X}_{n}), \quad \boldsymbol{Z} \coloneqq g(\boldsymbol{X}_{n+1}, \dots, \boldsymbol{X}_{n+m})$$这两个随机变量是独立的。


> **定理 2.31（相互独立随机变量的联合分布函数/分布密度函数满足乘积性质）**
> 一族 $n$ 维实值随机变量 $\boldsymbol{X}_{1}, \dots, \boldsymbol{X}_{m}: \Omega \rightarrow \mathbb{R}^{n}$ 相互独立，当且仅当 $$F_{\boldsymbol{X}_{1}, \dots, \boldsymbol{X}_{m}}(x_{1}, \dots, x_{m}) = F_{\boldsymbol{X}_{1}}(x_{1}) \cdots  F_{\boldsymbol{X}_{m}}(x_{m})$$其中 $x_{k} \in \mathbb{R}^{n}, k = 1, \dots, m$。
> 如果它们都存在对应的密度函数，这相当于 $$f_{\boldsymbol{X}_{1}, \dots, X_{n}}(x_{1}, \dots, x_{m}) = f_{\boldsymbol{X}_{1}}(x_{1}) \cdots  f_{\boldsymbol{X}_{m}}(x_{m})$$

**证明.**
一方面，假如 $\boldsymbol{X}_{1}, \dots, \boldsymbol{X}_{m}$ 相互独立，根据联合分布函数的定义，就有
$$
\begin{align}
F_{\boldsymbol{X}_{1}, \dots, \boldsymbol{X}_{m}}(x_{1}, \dots, x_{m}) &= P(\boldsymbol{X}_{1} \leqslant x_{1}, \dots, \boldsymbol{X}_{m} \leqslant x_{m}) \\
 & = P(\boldsymbol{X}_{1} \leqslant x_{1}) \cdots P(\boldsymbol{X}_{m} \leqslant x_{m})  & \text{随机变量的独立性} \\
 & = F_{\boldsymbol{X}_{1}}(x_{1}) \cdots  F_{\boldsymbol{X}_{m}}(x_{m}) & \text{分布函数的定义}
\end{align}
$$
另一方面，假如所有随机变量有对应的密度函数，对每个 $i=1, \dots, m$，选一个 $A_{i} \in \mathcal{U}(\boldsymbol{X}_{i})$ 所以存在某个 $B_{i} \in \mathcal{B}$，使得 $A_{i} = \boldsymbol{X}_{i}^{-1}(B_{i})$。因此
$$
\begin{align}
P(A_{1} \cap \cdots  \cap A_{m})  & = P(\boldsymbol{X}_{1} \in B_{1}, \dots, \boldsymbol{X}_{m} \in B_{m}) \\
 & = \int_{B_{1} \times \cdots  \times B_{m}} f_{\boldsymbol{X}_{1}, \dots, \boldsymbol{X}_{m}}(x_{1}, \dots, x_{m}) \, \mathrm d{x_{1}} \cdots \mathrm{d} x_{m} \\
 & = \left( \int_{B_{1}} f_{\boldsymbol{X}_{1}}(x_{1}) \, \mathrm d{x_{1}}  \right) \cdots  \left( \int_{B_{m}} f_{\boldsymbol{X}_{m}}(x_{m}) \, \mathrm d{x_{m}}  \right)  & \text{第二个条件} \\
 & = P(\boldsymbol{X}_{1} \in B_{1}) \cdots P(\boldsymbol{X}_{m} \in B_{m}) \\
 & = P(A_{1}) \cdots  P(A_{m})
\end{align}
$$
因此 $\mathcal{U}(\boldsymbol{X}_{1}), \dots, \mathcal{U}(\boldsymbol{X}_{m})$ 是相互独立的 $\sigma$-代数。


> **定理 2.32（相互独立且存在期望的随机变量的联合期望等于单独期望的乘积）**
> 一族实值随机变量 $X_{1}, \dots, X_{m}$ 相互独立，且 $E(|X_{i}|) < \infty, i = 1, \dots, m$，则有 $$\begin{align}E(|X_{1}\cdots X_{m}|) &< \infty \\E(X_{1}\cdots X_{m}) & =E(X_{1}) \cdots E(X_{m}).\end{align}$$

**证明.**
假设每个随机变量都有界，且存在对应的密度函数，于是
$$
\begin{align}
E(X_{1}, \dots, X_{m}) & = \int_{\mathbb{R}^{m}} x_{1}\cdots x_{m}f_{X_{1}, \dots, X_{m}}(x_{1}, \dots, x_{m}) \, \mathrm d{x_{1}\dots x_{m}} \\
 & =  \left( \int_{\mathbb{R}} x_{1}f_{X_{1}}(x_{1}) \, \mathrm d{x_{1}}  \right)\cdots \left( \int_{\mathbb{R}} x_{m}f_{X_{m}}(x_{m})  \, \mathrm d{x_{m}}  \right) & \text{密度函数性质、拆开积分区域} \\
 & = E(X_{1}) \cdots  E(X_{m})
\end{align}
$$

> **定理 2.33（相互独立方差存在的随机变量之和的方差等于方差之和）**
> 一族实值随机变量 $X_{1}, \dots, X_{m}$ 相互独立，且 $V(X_{i}) < \infty, i = 1, \dots, m$，则有 $$V(X_{1} + \cdots  + X_{m}) = V(X_{1}) + \cdots  + V(X_{m}).$$

**证明.**
我们用归纳法证明。当 $m=2$ 时，令 $m_{1} = E(X_{1}), m_{2} = E(X_{2})$，于是有 $E(X_{1} + X_{2}) = m_{1} + m_{2}$，以及
$$
\begin{align}
V(X_{1}+X_{2})  & = \int_{\Omega} (X_{1}+X_{2} - (m_{1}+m_{2}))^{2} \, \mathrm d{P}  \\
 & = \int_{\Omega} (X_{1} - m_{1})^{2} \, \mathrm d{P}  + \int_{\Omega} (X_{2} - m_{2})^{2}  \, \mathrm d{P} + 2\int_{\Omega} (X_{1}-m_{1})(X_{2}-m_{2}) \, \mathrm d{P}  \\
 & = V(X_{1}) + V(X_{2}) + 2E\big[ (X_{1} - m_{1})(X_{2} - m_{2}) \big] \\

 & = V(X_{1}) + V(X_{2}) + \underbrace{ 2E\big[X_{1} - m_{1}\big] E\big[X_{2} - m_{2}\big] }_{ 0 }  & \text{定理 2.32}\\
\end{align}
$$
然后我们就可以用 2.30 不断构造新的随机变量，完成我们的归纳法证明。

## 2.4 一些概率论中的工具和方法
### 2.4.1 Chebyshev 不等式

> **引理 2.34（Chebyshev）**
> $\boldsymbol{X}$ 是一个随机变量，$p$ 满足 $1 \leqslant p < \infty$，则对任意 $\lambda > 0$，有 $$P(|\boldsymbol{X}| \geqslant \lambda) \leqslant \frac{1}{\lambda^{p}} E(|\boldsymbol{X}|^{p})$$

**证明.**
$$
E(|\boldsymbol{X}|^{p}) = \int_{\Omega} |\boldsymbol{X}|^{p} \, \mathrm d{P} \geqslant \int_{|\boldsymbol{X}| \geqslant \lambda} |\boldsymbol{X}|^{p} \, \mathrm d{P} \geqslant \lambda^{p}P(|\boldsymbol{X}|\geqslant\lambda). 
$$

### 2.4.2 Borel–Cantelli 引理

<<<<<<< HEAD:SDE/Evans-随机微分方程导论/第2章 概率论速成.md
> **定义 2.35（无限发生的事件）**
> 给定概率空间中的事件序列 $A_{1}, \dots, A_{n}, \dots$，其中发生无限次的事件的集合可以写为 $$\bigcap_{n=1}^{\infty} \bigcup_{m=n}^{\infty} A_{m} = \limsup_{ n \to \infty } A_{n}.$$记作 $A_{n}\;i.o.$

定义中里面的可数无穷并说的是确定一个 $n$，然后把所有指标大于 $n$ 的事件收集起来；前面一个无穷交相当于取了一个极限，所有只在事件序列中出现有限次的点 $\omega$ 都会被过滤掉，剩下的就是发生了无限次的事件。例如掷两枚硬币，第一枚是理想的硬币，一直掷下去就会得到 $THTTH H T\cdots$ 这样的序列，正面和翻面都会出现无限次，因此对应的发生无限次的事件的集合就是 $\{ T, H \}$；假如第二枚硬币是做了手脚的，扔了几次之后每次抛掷得到的结果总是正面，对应发生无限次的事件的集合就是 $\{ H \}$ 因为 $T$ 只发生了有限次，它就在上面去极限的过程中被过滤掉了。

> **引理 2.36（Bodel-Cantelli）**
> 如果一个事件序列 $A_{1}, \dots$ 满足 $\displaystyle \sum\limits_{n=1}^{\infty} P(A_{n}) < \infty$，则 $$P(A_{n}\;i.o.) = 0.$$

**证明.**
根据定义，对每个 $n$，有
$$
P(A_{n}\;i.o.) = P\left(\bigcap_{n=1}^{\infty} \bigcup_{m=n}^{\infty} A_{m} \right) \leqslant P\left( \bigcup_{m=n}^{\infty}A_{m}  \right) \leqslant \sum\limits_{m=n}^{\infty} P(A_{m}).
$$
因为级数 $\displaystyle \sum\limits_{n=1}^{\infty} P(A_{n}) < \infty$，令 $n \rightarrow \infty$，就能得到 $P(A_{n}\;i.o.) \rightarrow 0$。
=======

>>>>>>> 9c686b9 (update):Maths/SDE/Evans-随机微分方程导论/第2章 概率论速成.md

### 2.4.3 特征函数
## 2.5 大数定律和中心极限定理
### 2.5.1 独立同分布的随机变量
### 2.5.2 强大数定律
### 2.5.3 扰动和 Laplace-De Moivre 定理
### 2.5.4 中心极限定理
## 2.6 条件期望
### 2.6.1 动机
### 2.6.2 条件分布的第一种构造
### 2.6.3 条件分布的第二种构造
### 2.6.4 条件分布的诸性质
## 2.7 鞅
### 2.7.1 定义
### 2.7.2 鞅的诸不等式


 
